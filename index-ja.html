<!DOCTYPE html>
<html lang="jp">
<meta charset="UTF-8">
<link href="./css/bootstrap.min.css" rel="stylesheet">

<head>
		<!-- Global site tag (gtag.js) - Google Analytics -->
		<script async src="https://www.googletagmanager.com/gtag/js?id=UA-137791530-1"></script>
		<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());
	
		gtag('config', 'UA-137791530-1');
		</script>
	</head>

<body>
	<nav class="navbar mynav navbar-light navbar-expand-sm sticky-top" style="background-color: #00ccbb; margin-bottom: 10px">
  		<a class="navbar-brand" href="#">Home</a>
  		<button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      		<span class="navbar-toggler-icon"></span>
      	</button>
  		<div class="collapse navbar-collapse" id="navbarSupportedContent">
	    	<ul class="navbar-nav mr-auto">
	      		<li class="nav-item">
	        		<a class="nav-link" href="./index-ja.html#Education">Education</a>
	      		</li>
	      		<li class="nav-item">
	        		<a class="nav-link" href="./index-ja.html#Research">Research</a>
	      		</li>
	      		<li class="nav-item">
	        		<a class="nav-link" href="./index-ja.html#Awards">Awards</a>
	      		</li>
	      		<li class="nav-item">
	      			<a class="nav-link" href="./index-ja.html#Publications">Publications</a>
				</li>
				<li class="nav-item">
        			<a class="nav-link" href="./index-ja.html#Grants">Grants</a>
        		</li>  
	      		<li>
	      			<a class="nav-link" href="./index.html">EN</a>
	      		</li>
	    	</ul>
	    </div>
 	</nav>

 	<div class="content">
 		<div class="row justify-content-start" >
 			<div class="col-sm-2">
 				<img src="ueno-sei.jpg" class="img-thumbnail" width="200px" alt="image"/>
 			</div>
 			<div class="col-sm-10">
 				<h3>上乃 聖</h3>
 				名古屋工業大学 大学院 工学研究科 情報工学プログラム 助教
 				<p>sei.ueno[at]nitech.ac.jp</p>
 			</div>
 		</div>
 	</div>
 	<h3 class="bar" id="Education">学歴</h3>
 		<ul>
 			<li>平成25年4月 同志社大学 理工学部 情報システムデザイン学科 入学</li>
 			<li>平成29年3月 同志社大学 理工学部 情報システムデザイン学科 卒業</li>
			<li>平成29年3月 京都大学大学院 情報学研究科 知能情報学専攻 修士課程 入学</li>
			<li>平成31年3月 京都大学大学院 情報学研究科 知能情報学専攻 修士課程 修了</li>
			<li>平成31年4月 京都大学大学院 情報学研究科 知能情報学専攻 博士後期課程 進学</li>
			<li>令和 4年3月 京都大学大学院 情報学研究科 知能情報学専攻 博士後期課程 修了</li>
 		</ul>
 	<h3 class="bar" id="Research">研究</h3>
 		<ul>
 			<li>Speech Recognition</li>
 			<li>Speech Synthesis</li>
 			<!-- <li>~</li> -->
 		</ul>
 	<h3 class="bar" id="Awards">受賞</h3>
 		<ul>
			<li><b>上乃聖</b>, 河原達也. 
				「音声認識のデータ拡張のための合成音声の周波数スペクトログラム強調」情報処理学会 情報処理学会, 2021, <b>山下記念研究賞.</b></li>			
			<li><b>上乃聖</b>, 稲熊寛文, 三村正人, 河原達也. 
				「文字単位のモデルを併用した単語単位のEnd-to-End音声認識」日本音響学会研究発表会講演論文集, 3-8-5, 春季2018, <b>学生優秀賞受賞.</b></li>
 			<li><b>上乃聖</b>, 森谷崇史, 三村正人, 坂井信輔, 篠原雄介, 山口義和, 青野裕司, 河原達也. 
				 「転移学習による注意機構付き単語単位音声認識の適応」電子情報通信学会技術研究報告, SP2018-23, 2018, <b>学生ポスター賞受賞.</b></li>
 			<li><b>上乃聖</b>, 三村正人, 坂井信輔, 河原達也. 「End-to-End音声合成を用いた単語単位End-to-End音声認識のデータ拡張」情報処理学会研究報告, SLP-125-2, 2018, <b>学生論文賞受賞.</b></li>
 		</ul>
	<h3 class="bar" id="Publications">Journal papers (first author)</h3>
 		<ol>
			<li><b>Sei Ueno</b>, Masato Mimura, Shinsuke Sakai, Tatsuya Kawahara: Synthesizing Waveform Sequence-to-sequence to Augment Training Data for Sequence-to-sequence Speech Recognition. Acoustical Science and Technology, Vol.42, Issue 6 pp.333-343, 2021.</li> 
		 </ol>
 	<h3 class="bar" id="Publications">International conference papers (first author)</h3>
 		<ol>
			<li><b>Sei Ueno</b>, Tatsuya Kawahara: Phone-Informed Refinement of Synthesized Mel Spectrogram for Data Augmentation in Speech Recognition. International Conference on Acoustics, Speech, and Signal Processing (ICASSP), pp.8572-8576, 2022.</li> 
			<li><b>Sei Ueno</b>, Masato Mimura, Shinsuke Sakai, Tatsuya Kawahara: Data Augmentation for ASR Using TTS Via a Discrete Representation, In Proc. IEEE Automatic Speech Recognition and Understanding Workshop (ASRU), pp.68-75, 2021.</li>
			<li><b>Sei Ueno</b>, Masato Mimura, Shinsuke Sakai, Tatsuya Kawahara: Multi-speaker Sequence-to-sequence Speech Synthesis for Data Augmentation in Acoustic-to-word Speech Recognition. IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), pp.6161-6165, 2019.</li> 
			<li><b>Sei Ueno</b>, Takafumi Moriya, Mimura Mimura, Shinsuke Sakai, YoshikazuYamaguchi, Yushi Aono, Tatsuya Kawahara: Encoder Transfer for Attention-based Acoustic-to-word Speech Recognition. INTERSPEECH, pp.2424-2428, 2018.</li>
			<li><b>Sei Ueno</b>, Hirofumi Inaguma, Masato Mimura, Tatsuya Kawahara: Acoustic-to-word Attention-based Model Complemented with Character-level CTC-based Model.International Conference on Acoustics, Speech, and SignalProcessing (ICASSP), pp.5804-5808, 2018.</li>
		 </ol>
	<h3 class="bar" id="Publications">International conference papers (co-author)</h3>
 		<ol>
			<li>Hayato Futami, Hirofumi Inaguma, <b>Sei Ueno</b>, Masato Mimura, Shinsuke Sakai, Tatsuya Kawahara: Non-Autoregressive Error Correction for CTC-based ASR with Phone-conditioned Masked LM. INTERSPEECH pp.3889–3893, 2022.</li>
			<li>Han Feng, <b>Sei Ueno</b>, Tatsuya Kawahara: End-to-End Speech Emotion Recognition Combined with Acoustic-to-Word ASR Model. INTERSPEECH, pp.501-505, 2020.</li>
			<li>Hayato Futami, Hirofumi Inaguma, <b>Sei Ueno</b>, Masato Mimura, Shinsuke Sakai, Tatsuya Kawahara: Distilling the Knowledge of BERT for Sequence-to-Sequence ASR. INTERSPEECH, pp.3635–3639, 2020.</li>
			<li>Viet-Trung Dang, Tianyu Zhao,<b>Sei Ueno</b>, Hirofumi Inaguma, Tatsuya Kawahara: End-to-End Speech-to-Dialog-Act Recognition. INTERSPEECH, pp.3910–3914, 2020.</li>
			<li>Kohei Matsuura, <b>Sei Ueno</b>, Masato Mimura, Shinsuke Sakai, Tatsuya Kawahara: Speech Corpus of Ainu Folklore and End-to-end Speech Recognition for Ainu Language. International Conference on Language Resources and Evaluation (LREC), pp.2622-2628,2020. </li>
 			<li>Takafumi Moriya, <b>Sei Ueno</b>, Yusuke Shinohara, Marc Delcroix, YoshikazuYamaguchi, Yushi Aono: Multi-task Learning with Augmentation Strategy for Acoustic-to-word Attention-based Encoder-decoder Speech Recognition. INTERSPEECH, pp.2399-2403, 2018.</li>
 			<li>Masato Mimura, <b>Sei Ueno</b>, Hirofumi Inaguma, Shinsuke Sakai, and Tatsuya Kawahara: Leveraging sequence-to-sequence Speech Synthesis for Enhancing Acoustic-to-word Speech Recognition. Workshop On Spoken Lan-guage Technology (SLT), pp.477-484, 2018.</li>
		</ol>
	<h3 class="bar" id="Grants">Grants / Fellowships</h3>
 		<ul>
 			<li>2019 – 2022 日本学術振興会 特別研究員 (DC1)</li>
		</ul>
	<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
  	<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
  	<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
</body>
</html>
