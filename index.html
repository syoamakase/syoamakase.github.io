<!DOCTYPE html>
<html lang="EN">
<meta charset="UTF-8">
<link href="./css/bootstrap.min.css" rel="stylesheet">

<head>
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=UA-137791530-1"></script>
	<script>
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());

	gtag('config', 'UA-137791530-1');
	</script>
</head>
<body>
	<nav class="navbar mynav navbar-light navbar-expand-sm sticky-top" style="background-color: #00ccbb; margin-bottom: 10px;">
  		<a class="navbar-brand" href="#">Home</a>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarSupportedContent">
      	<ul class="navbar-nav mr-auto">
        		<li class="nav-item">
          		<a class="nav-link" href="./index.html#Education">Education</a>
        		</li>
        		<li class="nav-item">
          		<a class="nav-link" href="./index.html#Research">Research</a>
        		</li>
        		<li class="nav-item">
          		<a class="nav-link" href="./index.html#Awards">Awards</a>
        		</li>
        		<li class="nav-item">
        			<a class="nav-link" href="./index.html#Publications">Publications</a>
				</li>
				<li class="nav-item">
        			<a class="nav-link" href="./index.html#Grants">Grants</a>
        		</li>
        		<li>
        			<a class="nav-link" href="./index-ja.html">JP</a>
        		</li>
      	</ul>
    </div>
 	</nav>

 	<div class="content">
 		<div class="row justify-content-start" >
 			<div class="col-sm-2">
 				<img src="ueno-sei.jpg" class="img-thumbnail" width="200px" alt="image"/>
 			</div>
 			<div class="col-sm-10">
 				<h3>Sei Ueno</h3>
 				Assistant Professor
                Nagoya Institute of Technology, Department of Computer Scitence, Japan
 				<p>sei.ueno[at]nitech.ac.jp</p>
 			</div>
 		</div>
 	</div>
 	<h3 class="bar" id="Education">Education</h3>
 		<ul>
 			<li>April 2022 – current: Assistant Professor of Nagoya Institute of Technology, Department of Computer Science, Japan.
 			<li>April 2019 – March 2022: Doctoral Program of Graduate School of Informatics, Kyoto University, Department Intelligence Science and Technology, Japan.
					Supervisor: Tatsuya Kawahara</li>
      		<li>April 2017 – March 2019: Master Program of Graduate School of Informatics,
					Kyoto University, Department of Intelligence Science
					and Technology, Japan.
					Supervisor: Tatsuya Kawahara</li>
 			<li>April 2013 – March 2017: Doshisha University Faculty of Science and Engineering,
					Department of Information Systems Design, Japan.</li>
 		</ul>
 	<h3 class="bar" id="Research">Research</h3>
 		<ul>
 			<li>Speech Recognition</li>
 			<li>Speech Synthesis</li>
 			<!-- <li>~</li> -->
 		</ul>
 	<h3 class="bar" id="Awards" >Awards</h3>
 		<ul>
			<li>March 2023: IPSJ Yamashita SIG Research Award</li>
 			<li>February 2019: Student Paper Award of The Information Processing Society of Japan, Special Interest Groups-Spoken Language Processing</li>
			<li>September 2018: Student Presentation Award of The Acoustical Society of Japan</li>
			<li>August 2018: Student Poster Award of The Institute of Electronics, Information and Communication Engineers, The Award of the Acoustical Society of Japan</li>	
			<li>September 2015: 1st Place, TOYOTA HSR Hackathon 2015</li>
 		</ul>
	<h3 class="bar" id="Publications">Journal papers (first author)</h3>
 		<ol>
            <li><b>Sei Ueno</b>, Lee Akinobu, Tatsuya Kawahara: Refining Synthesized Speech Using Speaker Information and Phone Masking for Data Augmentation of Speech Recognition. IEEE/ACM Transactions on Audio, Speech, and Language Processing, Vol.32, pp.3924-3933, 2024.</li>
            <li><b>Sei Ueno</b>, Lee Akinobu: Multi-setting acoustic feature training for data augmentation of speech recognition. Acoustical Science and Technology, Vol.45, Issue 4, pp.195-203, 2024.</li>
			<li><b>Sei Ueno</b>, Masato Mimura, Shinsuke Sakai, Tatsuya Kawahara: Synthesizing Waveform Sequence-to-sequence to Augment Training Data for Sequence-to-sequence Speech Recognition. Acoustical Science and Technology, Vol.42, Issue 6 pp.333-343, 2021.</li> 
		 </ol>
 	<h3 class="bar" id="Publications">International conference papers (first author)</h3>
 		<ol>
			<li><b>Sei Ueno</b>, Tatsuya Kawahara: Phone-Informed Refinement of Synthesized Mel Spectrogram for Data Augmentation in Speech Recognition. International Conference on Acoustics, Speech, and Signal Processing (ICASSP), pp.8572-8576, 2022.</li> 
			<li><b>Sei Ueno</b>, Masato Mimura, Shinsuke Sakai, Tatsuya Kawahara: Data Augmentation for ASR Using TTS Via a Discrete Representation, In Proc. IEEE Automatic Speech Recognition and Understanding Workshop (ASRU), pp.68-75, 2021.</li>
			<li><b>Sei Ueno</b>, Masato Mimura, Shinsuke Sakai, Tatsuya Kawahara: Multi-speaker Sequence-to-sequence Speech Synthesis for Data Augmentation in Acoustic-to-word Speech Recognition. IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), pp.6161-6165, 2019.</li> 
			<li><b>Sei Ueno</b>, Takafumi Moriya, Mimura Mimura, Shinsuke Sakai, YoshikazuYamaguchi, Yushi Aono, Tatsuya Kawahara: Encoder Transfer for Attention-based Acoustic-to-word Speech Recognition. INTERSPEECH, pp.2424-2428, 2018.</li>
			<li><b>Sei Ueno</b>, Hirofumi Inaguma, Masato Mimura, Tatsuya Kawahara: Acoustic-to-word Attention-based Model Complemented with Character-level CTC-based Model.International Conference on Acoustics, Speech, and SignalProcessing (ICASSP), pp.5804-5808, 2018.</li>
		 </ol>
	<h3 class="bar" id="Publications">International conference papers (co-author)</h3>
 		<ol>
			<li>Hayato Futami, Hirofumi Inaguma, <b>Sei Ueno</b>, Masato Mimura, Shinsuke Sakai, Tatsuya Kawahara: Non-Autoregressive Error Correction for CTC-based ASR with Phone-conditioned Masked LM. INTERSPEECH pp.3889–3893, 2022.</li>
			<li>Han Feng, <b>Sei Ueno</b>, Tatsuya Kawahara: End-to-End Speech Emotion Recognition Combined with Acoustic-to-Word ASR Model. INTERSPEECH, pp.501–505, 2020.</li>
			<li>Hayato Futami, Hirofumi Inaguma, <b>Sei Ueno</b>, Masato Mimura, Shinsuke Sakai, Tatsuya Kawahara: Distilling the Knowledge of BERT for Sequence-to-Sequence ASR. INTERSPEECH, pp.3635–3639, 2020.</li>
			<li>Viet-Trung Dang, Tianyu Zhao,<b>Sei Ueno</b>, Hirofumi Inaguma, Tatsuya Kawahara: End-to-End Speech-to-Dialog-Act Recognition. INTERSPEECH, pp.3910–3914, 2020.</li>
			<li>Kohei Matsuura, <b>Sei Ueno</b>, Masato Mimura, Shinsuke Sakai, Tatsuya Kawahara: Speech Corpus of Ainu Folklore and End-to-end Speech Recognition for Ainu Language. International Conference on Language Resources and Evaluation (LREC), pp.2622-2628,2020. </li>
 			<li>Takafumi Moriya, <b>Sei Ueno</b>, Yusuke Shinohara, Marc Delcroix, YoshikazuYamaguchi, Yushi Aono: Multi-task Learning with Augmentation Strategy for Acoustic-to-word Attention-based Encoder-decoder Speech Recognition. INTERSPEECH, pp.2399-2403, 2018.</li>
 			<li>Masato Mimura, <b>Sei Ueno</b>, Hirofumi Inaguma, Shinsuke Sakai, and Tatsuya Kawahara: Leveraging sequence-to-sequence Speech Synthesis for Enhancing Acoustic-to-word Speech Recognition. Workshop On Spoken Lan-guage Technology (SLT), pp.477-484, 2018.</li>
		</ol>
	<h3 class="bar" id="Grants">Grants / Fellowships</h3>
 		<ul>
 			<li>2019 – 2022 Japan Society for the Promotion of Science (JSPS) Research Fellowship for Young Scientists (DC1)</li>
		</ul>
	<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
</body>
</html>
